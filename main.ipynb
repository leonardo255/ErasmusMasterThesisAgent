{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "321ad94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import init_chat_model\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import json\n",
    "import os\n",
    "from src.agents.dimension_extractor import DimensionExtractor\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93a0014e",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "anthropic = init_chat_model(\n",
    "    \"anthropic:claude-haiku-4-5\",\n",
    "    temperature=0.5,\n",
    "    timeout=30,\n",
    "    max_tokens=5000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80838956",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR    = \"data\"\n",
    "PARSED_DIR  = \"data/papers\"\n",
    "OUTPUT_DIR = \"data/output\"\n",
    "GOLD_DIR    = \"data/evaluation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "418c76a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_MODEL = anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b1ec3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor_agent = DimensionExtractor(LLM_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9069415f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON data\n",
    "def parse_json(doc_id: str):\n",
    "    parsed_json_path = os.path.join(PARSED_DIR, doc_id + \".pdf.json\")\n",
    "    with open(parsed_json_path, \"r\") as f:\n",
    "        parsed_json = json.load(f)\n",
    "    \n",
    "    return parsed_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96d7f05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_paper(doc_id:str):\n",
    "\n",
    "    tqdm.write(f\"Analyzing paper ID: {doc_id}\")\n",
    "    output_path = os.path.join(OUTPUT_DIR, doc_id + \".pdf.json\")\n",
    "\n",
    "    parsed_json = parse_json(doc_id)\n",
    "\n",
    "    tqdm.write(\"Analysing dimensions...\")\n",
    "    content_output = extractor_agent.go_to_work(user_instructions=f\"Please analyse and extract the following input:\", input_data=parsed_json)\n",
    "\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(content_output, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8cc78e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assembly_csv():\n",
    "    doc_ids = sorted([f.stem for f in Path(OUTPUT_DIR).glob(\"*.json\")])\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for doc_id in tqdm(doc_ids, desc=\"Assembling CSV\"):\n",
    "        pass\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # Save CSV\n",
    "    df.to_csv(\"data/output.csv\", index=False, sep=\";\", encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "189f7d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing paper ID: 1.Many hands make light work\n",
      "Analysing dimensions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type Dimensions is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m DOC_IDS = \u001b[38;5;28msorted\u001b[39m([\u001b[38;5;28mid\u001b[39m.removesuffix(\u001b[33m'\u001b[39m\u001b[33m.pdf.json\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mid\u001b[39m \u001b[38;5;129;01min\u001b[39;00m os.listdir(PARSED_DIR)])\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m doc_id \u001b[38;5;129;01min\u001b[39;00m tqdm(DOC_IDS):\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[43manalyze_paper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36manalyze_paper\u001b[39m\u001b[34m(doc_id)\u001b[39m\n\u001b[32m      9\u001b[39m content_output = extractor_agent.go_to_work(user_instructions=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPlease analyse and extract the following input:\u001b[39m\u001b[33m\"\u001b[39m, input_data=parsed_json)\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(output_path, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_ascii\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/Cellar/python@3.12/3.12.12/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/__init__.py:179\u001b[39m, in \u001b[36mdump\u001b[39m\u001b[34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[39m\n\u001b[32m    173\u001b[39m     iterable = \u001b[38;5;28mcls\u001b[39m(skipkeys=skipkeys, ensure_ascii=ensure_ascii,\n\u001b[32m    174\u001b[39m         check_circular=check_circular, allow_nan=allow_nan, indent=indent,\n\u001b[32m    175\u001b[39m         separators=separators,\n\u001b[32m    176\u001b[39m         default=default, sort_keys=sort_keys, **kw).iterencode(obj)\n\u001b[32m    177\u001b[39m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[32m    178\u001b[39m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/Cellar/python@3.12/3.12.12/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/encoder.py:439\u001b[39m, in \u001b[36m_make_iterencode.<locals>._iterencode\u001b[39m\u001b[34m(o, _current_indent_level)\u001b[39m\n\u001b[32m    437\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCircular reference detected\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    438\u001b[39m     markers[markerid] = o\n\u001b[32m--> \u001b[39m\u001b[32m439\u001b[39m o = \u001b[43m_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    440\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[32m    441\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/Cellar/python@3.12/3.12.12/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/encoder.py:180\u001b[39m, in \u001b[36mJSONEncoder.default\u001b[39m\u001b[34m(self, o)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[32m    162\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[33;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[33;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    178\u001b[39m \n\u001b[32m    179\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    181\u001b[39m                     \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mis not JSON serializable\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: Object of type Dimensions is not JSON serializable"
     ]
    }
   ],
   "source": [
    "DOC_IDS = sorted([id.removesuffix('.pdf.json') for id in os.listdir(PARSED_DIR)])\n",
    "\n",
    "for doc_id in tqdm(DOC_IDS):\n",
    "    analyze_paper(doc_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
